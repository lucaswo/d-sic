{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import ImageStat\n",
    "import h5py\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# run jupyter with THEANO_FLAGS='floatX=float32,device=gpu'\n",
    "# or include \n",
    "#   [global]\n",
    "#   floatX = float32\n",
    "#   device = gpu0\n",
    "# to ~/.theanorc\n",
    "\n",
    "# Also, add \n",
    "#   [cuda]\n",
    "#   root = /usr/local/cuda\n",
    "# to ~/.theanorc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "nb_epoch = 50\n",
    "samples_per_epoch = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, filter and label location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = pd.read_hdf(\"data/backup/complete_paths.h5\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = locations[((locations['ice'] > 0) & (locations['ice'] <= 100)) | (locations[\"ice\"] == 255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def building_classes(ice_conc):\n",
    "    if ice_conc > 0 and ice_conc <= 100: # ten classes of ice concentration\n",
    "        return 1#int(np.ceil(ice_conc/10))\n",
    "    #elif ice_conc == 255: # ocean\n",
    "    #    return 0\n",
    "    else:  # coast\n",
    "        return 0# 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locations[\"labels\"] = locations[\"ice\"].map(building_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perceived brightness\n",
    "def brightness(img):\n",
    "    stat = ImageStat.Stat(img)\n",
    "    r,g,b = stat.mean\n",
    "    return np.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "\n",
    "def brightness_gray(img):\n",
    "    stat = ImageStat.Stat(img)\n",
    "    return stat.mean[0]\n",
    "\n",
    "def train_generator(images, labels, batch_size=32):\n",
    "    \n",
    "    #train_datagen = ImageDataGenerator(\n",
    "    #    rescale=1./255,\n",
    "    #    shear_range=0.2,\n",
    "    #    zoom_range=0.2,\n",
    "    #    horizontal_flip=True)\n",
    "    labels = np_utils.to_categorical(labels, nb_classes=np.max(labels) + 1)\n",
    "    \n",
    "    i = -1\n",
    "    while True:\n",
    "        batch = np.ndarray((batch_size, 3, 192, 256))\n",
    "        batch_label = np.ndarray((batch_size, 2))\n",
    "        \n",
    "        step = 0\n",
    "        while step < batch_size:\n",
    "            i = (i+1) % len(images)\n",
    "            #i = random.randrange(len(images))\n",
    "            try:\n",
    "                image = load_img(images[i], target_size=(192, 256))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            \n",
    "            # only use images with sufficient brightness, margin choosen by fair dice rolls\n",
    "            if brightness(image) > 70.0:\n",
    "                batch[step] = img_to_array(image)/255#.reshape(1,3,192,256)/255\n",
    "                batch_label[step] = labels[i]\n",
    "                step += 1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        #print(i, step)\n",
    "        \n",
    "        yield batch, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "for x,y in train_generator(locations[\"image\"], locations[\"labels\"], model, batch_size=1):\n",
    "    \n",
    "    print(x.shape,y.shape)\n",
    "    n += 1\n",
    "    \n",
    "    if n == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3,192,256)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = train_generator(locations[\"image\"], locations[\"labels\"], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.fit_generator(generator, samples_per_epoch=10000, nb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#x = load_img(\"data/images/remote/20111120-2201.jpeg\", target_size=(192, 256))\n",
    "x = load_img(\"data/images/remote/20111120-2201.jpeg\")\n",
    "#ground = \n",
    "\n",
    "#y = model.predict(img_to_array(x).reshape(1,3,192,256)/255)[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
